{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7b5d02",
   "metadata": {},
   "source": [
    "# 머신러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70398303",
   "metadata": {},
   "source": [
    "- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\n",
    "\n",
    "\n",
    "- 훈련 세트 : 시스템이 학습하는 데 사용하는 샘플\n",
    "\n",
    "\n",
    "- 훈련 사례(샘플) : 시스템이 학습하는 데 사용하는 샘플\n",
    "\n",
    "\n",
    "- 훈련 데이터\n",
    "\n",
    "\n",
    "- 성능 측정 : 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5fab96",
   "metadata": {},
   "source": [
    "# 왜 머신러닝 사용?\n",
    "\n",
    "- 자동으로 학습하기 때문에 빠르고 편리함\n",
    "\n",
    "\n",
    "- 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있음\n",
    "    - **데이터 마이닝**\n",
    "    \n",
    "\n",
    "- 머신러닝의 뛰어난 부분\n",
    "    - 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 \n",
    "    - 전통적인 방식으로는 해결 방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있음\n",
    "    - 유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있음\n",
    "    - 복잡한 문제와 대량의 데이터에서 통찰 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146067f3",
   "metadata": {},
   "source": [
    "# 머신러닝 시스템의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1874bad",
   "metadata": {},
   "source": [
    "- 사람의 감독하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 준지도, 강화 학습)\n",
    "\n",
    "\n",
    "- 실시간으로 점진적인 학습을 하는지 아닌지 (온라인 학습과 배치 학습)\n",
    "\n",
    "\n",
    "- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지 (사례 기반 학습과 모델 기반 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ebfb5",
   "metadata": {},
   "source": [
    "## 지도학습과 비지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60c7f3",
   "metadata": {},
   "source": [
    "**지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c49d3a",
   "metadata": {},
   "source": [
    "- 알고리즘에 주입하는 훈련 데이터에 '레이블'이라는 원하는 답이 포함됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118eb50d",
   "metadata": {},
   "source": [
    "- **분류**가 전형적인 지도 학습 작업\n",
    "\n",
    "\n",
    "- 예측 변수라 부르는 특성을 사용해 타깃을 예측하는 것이 **회귀**\n",
    "\n",
    "\n",
    "- 일부 회귀 알고리즘은 분류에 사용할 수 있음\n",
    "    - 분류에 널리 쓰이는 **로지스틱 회귀**는 클래스에 속할 확률을 출력\n",
    "    \n",
    "---\n",
    "<font color=red>지도 학습 알고리즘 (association rule learning)</font>\n",
    "1. k- 최근접 이웃\n",
    "2. 선형 회귀\n",
    "3. 로지스틱 회귀\n",
    "4. 서포트 벡터 머신\n",
    "5. 결정 트리와 랜덤 포레스트\n",
    "6. 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c7f1e",
   "metadata": {},
   "source": [
    "**비지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfdfa8",
   "metadata": {},
   "source": [
    "- 훈련 데이터에 레이블이 없음, 즉 아무런 도움 없이 학습해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e611303",
   "metadata": {},
   "source": [
    "---\n",
    "<font color=red>비지도 학습 알고리즘 (association rule learning)</font>\n",
    "\n",
    "<font color=red>1. 군집(clustering) (association rule learning)</font>\n",
    "- k-평균\n",
    "- DBSCAN\n",
    "- 계층 군집 분석(HCA)\n",
    "- 이상치 탐지와 특이치 탐지\n",
    "- 원-클래스\n",
    "- 아이솔레이션 포레스트\n",
    "\n",
    "<font color=red>2. 시각화와 차원 축소 (association rule learning)</font>\n",
    "- 주성분 분석(PCA)\n",
    "- 커널 PCA\n",
    "- 지역적 선형 임베딩(LLE)\n",
    "- t-SNE (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "<font color=red>3. 연관 규칙 학습 (association rule learning)</font>\n",
    "- 어프라이어리 (Apriori)\n",
    "- 이클렛 (Eclat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5a106",
   "metadata": {},
   "source": [
    "**계층 군집** \n",
    "- 알고리즘 사용시 각 그룹을 더 작은 그룹으로 세분화할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec83f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T15:23:16.942862Z",
     "start_time": "2023-01-12T15:23:16.930007Z"
    }
   },
   "source": [
    "**시각화** \n",
    "- 비지도 학습 알고리즘의 좋은 예임.\n",
    "- 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어줌\n",
    "- 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상하지 못한 패턴 발견 가능\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516320b8",
   "metadata": {},
   "source": [
    "**차원 축소**\n",
    "- 너무 많은 정보를 잃지 않으면서 데이터를 간소화하려는 작업\n",
    "- 상관관계가 있는 여러 특성을 하나로 합침\n",
    "- 두 특성을 하나의 특성으로 합칠 수 있음\n",
    "    - 이를 특성 추출이라 함\n",
    "    \n",
    "\n",
    "<font color=red>학습 속도 빨라지고 디스크와 메모리 차지하는 공간 줄어듦, 경우에 따라 성능이 좋아질 수 있음</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da64ef",
   "metadata": {},
   "source": [
    "**이상치 탐지**\n",
    "- 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거함\n",
    "- 훈련하는 동안 대부분 정상 샘플을 만나 이를 인식하도록 훈련함\n",
    "- 매우 비슷한 작업으로 **특이치 탐지**가 있음\n",
    "    - 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적\n",
    "    - 깨끗한 훈련 세트가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a2450",
   "metadata": {},
   "source": [
    "**연관 규칙 학습**\n",
    "- 대량의 데이터에서 특성 간의 흥미로운 관계를 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d739d",
   "metadata": {},
   "source": [
    "**준지도 학습**\n",
    "- 레이블이 없는 샘플이 많음\n",
    "- 일부만 레이블이 있는 데이터를 다룰 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc72087",
   "metadata": {},
   "source": [
    "- 심층 신뢰 신경망(DBN)은 여러 겹으로 쌓은 **제한된 볼츠만 머신(RBM)** 이라 불리는 비지도 학습에 기초함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296e8e9",
   "metadata": {},
   "source": [
    "**강화 학습**\n",
    "- 학습하는 시스템 : **에이전트** \n",
    "- 환경을 관찰하고 행동을 실행하고 그 결과로 **보상** 처럼 부정적인 보상에 해당하는 **벌점**을 받음\n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책**이라고 부르는 최상의 전략을 스스로 학습함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30042eac",
   "metadata": {},
   "source": [
    "1. 관찰\n",
    "2. 정책에 따라 행동을 선택\n",
    "3. 행동 실행!\n",
    "4. 보상이나 벌점을 받음\n",
    "5. 정책 수정(학습 단계)\n",
    "6. 최적의 정책을 찾을 때까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6340ee8",
   "metadata": {},
   "source": [
    "## 배치 학습과 온라인 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2cc22",
   "metadata": {},
   "source": [
    "- 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ab7f1",
   "metadata": {},
   "source": [
    "**배치 학습**\n",
    "- 점진적으로 학습할 수 없음\n",
    "- 가용한 데이터를 모두 사용해 훈련시킴\n",
    "- 학습한 것을 단지 적용만 함\n",
    "    - 이를 **오프라인 학습**이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77144aa",
   "metadata": {},
   "source": [
    "- 배치 학습 시스템이 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 새로운 버전을 처음부터 다시 훈련해야함\n",
    "    - 큰 비용이 발생함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f8b5c",
   "metadata": {},
   "source": [
    "**온라인 학습**\n",
    "- 데이터를 순차적으로 한 개씩 또는 **미니배치**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴\n",
    "- 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed7234",
   "metadata": {},
   "source": [
    "- 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템에 적합함\n",
    "- 컴퓨팅 자원이 제한된 경우에도 좋은 선택이 됨\n",
    "- **외부 메모리**학습이라고도 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355efe9d",
   "metadata": {},
   "source": [
    "- **학습률** : 변화하는 데이터에 얼마나 빠르게 적응할 것인지 알려주는 파라미터\n",
    "- 학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림\n",
    "- 학습률이 낮으면 시스템의 관성이 더 커져 더 느리게 학습됨\n",
    "    - 새로운 데이터에 있는 잡음이나 대표성이 없는 데이터 포인트에 덜 민감해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d516c6",
   "metadata": {},
   "source": [
    "- 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다는 점\n",
    "    - 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중지시켜야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bca5a2",
   "metadata": {},
   "source": [
    "## 사례 기반 학습과 모델 기반 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298efc5",
   "metadata": {},
   "source": [
    "**일반화**\n",
    "- 본 적 없는 새로운 데이터에서 좋은 예측을 만들어야 (일반화되어야) 한다는 뜻임\n",
    "- 새로운 샘플에 잘 작동하는 모델을 만드는 것이 목표임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93e1b4",
   "metadata": {},
   "source": [
    "**사례 기반 학습**\n",
    "- __유사도__ 측정 : 공통으로 포함한 특성을 추출\n",
    "- 훈련 샘플을 기억함으로써 학습함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc09c0",
   "metadata": {},
   "source": [
    "__모델 기반 학습__\n",
    "- 샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 예측에 사용하는 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af9bd0",
   "metadata": {},
   "source": [
    "- 데이터가 흩어져 있지만 모델링하여 일반화 가능해짐\n",
    "    - 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f425a92",
   "metadata": {},
   "source": [
    "$$삶의 만족도 = \\theta_0 + \\theta_1 \\times 1인당GDP$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9ef68",
   "metadata": {},
   "source": [
    "- 위 모델은 두 개의 __모델 파라미터__를 가짐\n",
    "    - 이를 통해 원하는 모델을 얻을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d42e0",
   "metadata": {},
   "source": [
    "- 모델을 사용하기 전에 파라미터를 정의해야함\n",
    "    - 측정 지표 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74154807",
   "metadata": {},
   "source": [
    "- 모델이 얼마나 좋은지 측정하는 **호용 함수** (또는 **적합도 함수**)를 정의하거나 얼마나 **나쁜지** 측정하는 **비용 함수**를 정의할 수 있음\n",
    "    - 선형 회귀에서는 데이터의 사이의 거리를 재는 비용 함수를 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7c143",
   "metadata": {},
   "source": [
    "- 알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾음\n",
    "    - 이를 **훈련** 시킨다고 말함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409dd23",
   "metadata": {},
   "source": [
    "---\n",
    "더 좋은 모델을 만들기 위해서 더 많은 특성을 사용하거나, 좋은 훈련 데이터를 더 많이 모으거나, 더 강력한 모델을 선택해야 할 수 있음\n",
    "\n",
    "**요약**\n",
    "- 데이터를 분석\n",
    "- 모델을 선택\n",
    "- 훈련 데이터로 모델을 훈련시킴\n",
    "- 새로운 데이터에 모델을 적용해 예측을 하고,  이 모델이 잘 일반화되길 기대함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699328a",
   "metadata": {},
   "source": [
    "# 머신러닝의 주요 도전 과제\n",
    "\n",
    "- 나쁜 알고리즘과 나쁜 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635e1ff",
   "metadata": {},
   "source": [
    "## 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "- 누락된 데이터를 추가하면 모델이 크게 변경되고 잘 동작하지 않을 수 있음\n",
    "- 샘플이 작으면 **샘플링 잡음(우연에 의한 대표성 없는 데이터)** 이 생김\n",
    "- 매우 큰 샘플도 추출 방법이 잘못되면 대표성을 띠지 못하는 **샘플링 편향**이 생김"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f06234",
   "metadata": {},
   "source": [
    "## 낮은 품질의 데이터\n",
    "\n",
    "- 훈련 데이터가 에러, 이상치, 잡음으로 가득하면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것임\n",
    "- 훈련 데이터를 정제하는 것이 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28533e6",
   "metadata": {},
   "source": [
    "## 관련 없는 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d50bcf",
   "metadata": {},
   "source": [
    "- 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 학습할 수 있음\n",
    "- 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것임\n",
    "    - 이 과정을 **특성 공학**이라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b4313",
   "metadata": {},
   "source": [
    "**특성 공학**\n",
    "- **특성 선택** : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택함\n",
    "- **특성 추출** : 특성을 결합하여 더 유용한 특성을 만듦, PCA가 도움이 될 수 있음\n",
    "- 새로운 데이터를 수집해 새 특성을 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebaa573",
   "metadata": {},
   "source": [
    "## 훈련 데이터 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b44d4d",
   "metadata": {},
   "source": [
    "<font color=red>과대적합</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d58df",
   "metadata": {},
   "source": [
    "- 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다는 뜻\n",
    "\n",
    "\n",
    "- DNN과 같은 복잡한 모델은 훈련 세트에 잡음이 많거나 데이터셋이 너무 작으면 잡음이 섞인 패턴을 감지하게 됨\n",
    "    - 이런 패턴은 새로운 샘플에 일반화 하지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57879b",
   "metadata": {},
   "source": [
    "과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어남\n",
    "\n",
    "**해결 방법**\n",
    "- 파라미터 수가 적은 모델을 선택하거나, 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킴\n",
    "- 훈련 데이터를 더 많이 모음\n",
    "- 훈련 데이터의 잡음을 줄임 (오류 데이터 수정과 이상치 제거)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08380449",
   "metadata": {},
   "source": [
    "- 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 **규제**라고 함\n",
    "- 훈련 데이터에 모델을 맞추기 위한 **자유도**를 부여할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d879011",
   "metadata": {},
   "source": [
    "- 학습하는 동안 적용할 규제의 양은 **하이퍼파라미터**가 결정함\n",
    "- 하이퍼파라미터는 학습 알고리즘의 파라미터임\n",
    "- 학습 알고리즘에 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d3041",
   "metadata": {},
   "source": [
    "## 훈련 데이터 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c881246",
   "metadata": {},
   "source": [
    "**과소적합**\n",
    "- 과대적합과 반대\n",
    "- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어남\n",
    "\n",
    "**해결방법**\n",
    "- 모델 파라미터가 더 많은 강력한 모델을 선택\n",
    "- 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)\n",
    "- 모델의 제약을 줄임(규제 하이퍼파라미터를 감소시킴)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed36f5",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만듦\n",
    "- 여러 종류의 머신러닝 시스템이 존재. 지도 학습과 비지도 학습, 배치 학습과 온라인 학습, 사례 기반 학습과 모델 기반 학습 등\n",
    "- 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입함\n",
    "    - 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하고 새로운 데이터에서도 좋은 예측을 만들 거라 기대함\n",
    "    - 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 유사도 측정을 사용하여 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플에 일반화함\n",
    "- 훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않음\n",
    "- 모델이 너무 단순하거나, 너무 복잡하지 않아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ded57a",
   "metadata": {},
   "source": [
    "# 테스트와 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9dd70",
   "metadata": {},
   "source": [
    "- 모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해보는 것임\n",
    "---\n",
    "훈련 데이터를 **훈련 세트**와 **테스트 세트**로 나누는 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de984e",
   "metadata": {},
   "source": [
    "**일반화 오차(외부 샘플 오차)** : 새로운 샘플에 대한 오류 비율\n",
    "- 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻음\n",
    "- 이전값은 이전에 본 적이 없는 새로운 샘플에 모델이 얼마나 잘 작동할지 알려줌\n",
    "\n",
    "<font color='red'>훈련 오차가 낮지만 일반화 오차가 높다면 과대적합</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b934f",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝과 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ede20b",
   "metadata": {},
   "source": [
    "- 일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들어서 문제가 생김\n",
    "- 새로운 데이터에 잘 작동하지 않을 수 있음\n",
    "\n",
    "<font color='red'>홀드아웃 검증</font>\n",
    "- 위와 같은 문제를 해결할 수 있는 방법임\n",
    "- 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택함\n",
    "- **검증 세트**라고 부름\n",
    "\n",
    "1. 훈련 세트(검증 세트 제외)로 훈련 \n",
    "2. 검증 세트에서 가장 높은 성능을 내는 모델을 선택 \n",
    "3. 최선의 모델을 전체 훈련 세트(검증 세트 포함)에서 다시 훈련하여 최종 모델을 만듦\n",
    "4. 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정함\n",
    "\n",
    "---\n",
    "- 검증 세트가 너무 작으면 정확하게 평가하지 못함\n",
    "- 검증 세트가 너무 크면 훈련 세트가 전체 훈련 세트보다 너무 작아짐\n",
    "\n",
    "\n",
    "<font color='red'>교차 검증으로 해결</font>\n",
    "- 작은 검증 세트를 여러 개 사용해 반복적인 교차 검증을 수행\n",
    "- 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가함\n",
    "- 훨씬더 정확한 성능을 측정할 수 있음\n",
    "- 훈련 시간이 늘어남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779c7ee",
   "metadata": {},
   "source": [
    "**데이터 불일치**\n",
    "- 많은 양의 훈련 데이터가 있지만 실제 데이터에 완벽하게 대표하지 못할 수 있음\n",
    "- 따라서 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야 함\n",
    "- 훈련 데이터에서 또 다른 세트를 만들어서 대응\n",
    "- **훈련-개발 세트**\n",
    "- 모델을 훈련한 다음 훈련-개발 세트에서 평가함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
